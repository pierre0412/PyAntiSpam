#!/usr/bin/env python3
"""Script pour forcer le r√©entra√Ænement ML avec les VRAIES donn√©es utilisateur"""

import json
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any

# Import des modules PyAntiSpam
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from pyantispam.config import ConfigManager
from pyantispam.ml.ml_classifier import MLClassifier
from pyantispam.stats.stats_manager import StatsManager
from pyantispam.learning.feedback_processor import FeedbackProcessor

def collect_user_feedback_samples() -> List[Dict[str, Any]]:
    """Collecter les √©chantillons d'entra√Ænement depuis les feedbacks utilisateur r√©els"""
    training_samples = []

    # 1. Charger les overrides utilisateur depuis llm_cache.json
    llm_cache_file = Path("data/llm_cache.json")
    user_override_samples = []

    if llm_cache_file.exists():
        try:
            with open(llm_cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)

            user_overrides = {k: v for k, v in cache_data.items()
                            if v.get('method') == 'user_feedback' and v.get('override')}

            # Essayer de reconstituer des √©chantillons √† partir des overrides
            # Note: Les overrides n'ont que la d√©cision, pas les donn√©es email compl√®tes
            for fingerprint, override in user_overrides.items():
                # Cr√©er un √©chantillon minimal bas√© sur l'override
                is_spam = override.get('action') == 'SPAM'

                # √âchantillon minimaliste pour l'entra√Ænement
                sample = {
                    'email_data': {
                        'sender_email': f'user_feedback_{fingerprint[:8]}@example.com',
                        'sender_domain': 'user-feedback.local',
                        'subject': f'User feedback sample {fingerprint[:8]}',
                        'text_content': f'User feedback training sample for {"spam" if is_spam else "ham"} classification'
                    },
                    'is_spam': is_spam
                }
                user_override_samples.append(sample)

            logging.info(f"Trouv√© {len(user_overrides)} overrides utilisateur dans le cache LLM")
            logging.info(f"Cr√©√© {len(user_override_samples)} √©chantillons √† partir des overrides")

        except Exception as e:
            logging.warning(f"Erreur lecture cache LLM: {e}")
            user_overrides = {}
    else:
        user_overrides = {}

    # Ajouter les √©chantillons des overrides
    training_samples.extend(user_override_samples)

    # 2. Essayer de charger l'ancien training_data.json (m√™me corrompu)
    training_data_file = Path("data/training_data.json")
    if training_data_file.exists():
        try:
            with open(training_data_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Essayer de r√©parer le JSON corrompu
            if content and not content.strip().endswith('}') and not content.strip().endswith(']'):
                # Fichier tronqu√©, essayer de le fermer proprement
                if content.strip().endswith(','):
                    content = content.strip()[:-1]  # Enlever la virgule finale

                if content.count('[') > content.count(']'):
                    content += ']'  # Fermer le tableau
                elif content.count('{') > content.count('}'):
                    content += '}'  # Fermer l'objet

            # Essayer de parser le JSON r√©par√©
            try:
                existing_samples = json.loads(content)
                if isinstance(existing_samples, list):
                    # Filtrer les √©chantillons valides
                    valid_samples = []
                    for sample in existing_samples:
                        if (isinstance(sample, dict) and
                            'email_data' in sample and
                            'is_spam' in sample and
                            isinstance(sample['email_data'], dict)):
                            valid_samples.append(sample)

                    training_samples.extend(valid_samples)
                    logging.info(f"R√©cup√©r√© {len(valid_samples)} √©chantillons depuis training_data.json")

            except json.JSONDecodeError:
                logging.warning("Impossible de r√©parer training_data.json, utilisation des donn√©es par d√©faut")

        except Exception as e:
            logging.warning(f"Erreur lecture training_data.json: {e}")

    # 3. Si pas assez de donn√©es r√©elles, ajouter les √©chantillons par d√©faut
    if len(training_samples) < 10:
        logging.info("Pas assez de donn√©es r√©elles, ajout d'√©chantillons par d√©faut")
        config_manager = ConfigManager()
        ml_classifier = MLClassifier(config_manager.config, data_dir="data")
        default_samples = ml_classifier.create_default_training_data()
        training_samples.extend(default_samples)

    # 4. D√©duplication par contenu email
    seen_fingerprints = set()
    unique_samples = []

    for sample in training_samples:
        # Cr√©er une empreinte unique bas√©e sur sender + subject + body
        email_data = sample.get('email_data', {})
        fingerprint = f"{email_data.get('sender_email', '')}{email_data.get('subject', '')}{str(email_data.get('text_content', email_data.get('body', '')))[:100]}"

        if fingerprint not in seen_fingerprints:
            seen_fingerprints.add(fingerprint)
            unique_samples.append(sample)

    logging.info(f"Total d'√©chantillons uniques pour l'entra√Ænement: {len(unique_samples)}")

    # Statistiques
    spam_count = sum(1 for s in unique_samples if s.get('is_spam'))
    ham_count = len(unique_samples) - spam_count
    logging.info(f"  - Spam: {spam_count}")
    logging.info(f"  - Ham: {ham_count}")

    return unique_samples

def main():
    """Force le r√©entra√Ænement ML avec les vraies donn√©es utilisateur"""
    logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
    logger = logging.getLogger(__name__)

    try:
        # Charger la configuration
        config_manager = ConfigManager()
        config = config_manager.config

        logger.info("üîç Collecte des √©chantillons d'entra√Ænement R√âELS...")

        # Collecter les vrais √©chantillons utilisateur
        training_samples = collect_user_feedback_samples()

        if not training_samples:
            logger.error("‚ùå Aucun √©chantillon d'entra√Ænement disponible")
            return False

        # Initialiser le classificateur ML
        ml_classifier = MLClassifier(config, data_dir="data")

        # R√©entra√Æner le mod√®le avec les VRAIES donn√©es
        logger.info(f"üöÄ D√©marrage du r√©entra√Ænement ML avec {len(training_samples)} √©chantillons R√âELS...")
        result = ml_classifier.train_with_samples(training_samples)

        if result["success"]:
            logger.info(f"‚úÖ R√©entra√Ænement r√©ussi avec de VRAIES donn√©es!")
            logger.info(f"   üìä Pr√©cision: {result.get('accuracy', 0):.3f}")
            logger.info(f"   üìß √âchantillons: {result.get('samples_count', 0)}")
            logger.info(f"   üóëÔ∏è  Spam: {result.get('spam_count', 0)}")
            logger.info(f"   ‚úÖ Ham: {result.get('ham_count', 0)}")

            # Mettre √† jour les statistiques
            stats_manager = StatsManager()
            stats_manager.record_ml_retrain(result)

            logger.info("üìà Statistiques mises √† jour")

            return True
        else:
            logger.error(f"‚ùå √âchec du r√©entra√Ænement: {result.get('error', 'Erreur inconnue')}")
            return False

    except Exception as e:
        logger.error(f"üí• Erreur lors du r√©entra√Ænement forc√©: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)